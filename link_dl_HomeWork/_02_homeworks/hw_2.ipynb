{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-25T09:48:05.802405Z",
     "start_time": "2024-10-25T09:48:05.775540Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import nn\n",
    "\n",
    "# 현재 작업 디렉토리로 설정 (Jupyter Notebook 호환)\n",
    "CURRENT_FILE_PATH = os.getcwd()\n",
    "\n",
    "# TitanicDataset: 학습 및 검증 데이터를 위한 Dataset 클래스 정의\n",
    "class TitanicDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        # 입력 데이터를 float 타입의 텐서로 변환하여 저장\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        # 타겟 레이블 데이터를 long 타입의 텐서로 변환하여 저장 (분류 문제를 위한 정수형)\n",
    "        self.y = torch.LongTensor(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        # 데이터셋의 전체 샘플 개수 반환\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 주어진 인덱스에 해당하는 샘플의 입력 데이터와 타겟 레이블 반환\n",
    "        feature = self.X[idx]\n",
    "        target = self.y[idx]\n",
    "        # 딕셔너리 형태로 반환하여 DataLoader에서 사용 가능\n",
    "        return {'input': feature, 'target': target}\n",
    "\n",
    "    def __str__(self):\n",
    "        # 데이터셋 정보 문자열로 출력 (데이터 크기, 입력, 타겟 형상 포함)\n",
    "        str = \"Data Size: {0}, Input Shape: {1}, Target Shape: {2}\".format(\n",
    "            len(self.X), self.X.shape, self.y.shape\n",
    "        )\n",
    "        return str"
   ],
   "outputs": [],
   "execution_count": 470
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- `TitanicDataset` <br>\n",
    "  입력 데이터를 텐서 형태로 변환해 학습 및 검증에 사용되는 데이터셋을 정의합니다. 학습 샘플의 개수를 반환하는 `__len__()` 메서드와 인덱스를 이용해 샘플을 가져오는 `__getitem__()` 메서드를 통해 `DataLoader`에서 배치를 생성할 수 있도록 합니다. <br>\n",
    "\n"
   ],
   "id": "a3223956e67b751d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T09:48:05.924867Z",
     "start_time": "2024-10-25T09:48:05.905824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TitanicTestDataset: 테스트 데이터를 위한 Dataset 클래스 정의 (타겟이 없기 때문에 input만 필요)\n",
    "class TitanicTestDataset(Dataset):\n",
    "    def __init__(self, X):\n",
    "        # 입력 데이터를 float 타입의 텐서로 변환하여 저장\n",
    "        self.X = torch.FloatTensor(X)\n",
    "\n",
    "    def __len__(self):\n",
    "        # 데이터셋의 전체 샘플 개수 반환\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 주어진 인덱스에 해당하는 샘플의 입력 데이터 반환\n",
    "        feature = self.X[idx]\n",
    "        return {'input': feature}\n",
    "\n",
    "    def __str__(self):\n",
    "        # 테스트 데이터셋 정보 문자열로 출력 (데이터 크기와 입력 형상 포함)\n",
    "        str = \"Data Size: {0}, Input Shape: {1}\".format(\n",
    "            len(self.X), self.X.shape\n",
    "        )\n",
    "        return str"
   ],
   "id": "f0fe78596f1f59d0",
   "outputs": [],
   "execution_count": 471
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- `TitanicTestDataset` <br>\n",
    "  테스트 데이터셋으로, 학습 데이터와는 다르게 타겟 라벨이 포함되지 않으며 입력 데이터만 저장합니다. 이를 통해 테스트 데이터에 대한 예측을 수행할 수 있습니다. <br>\n"
   ],
   "id": "52f610a72e41bed5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T09:48:05.969675Z",
     "start_time": "2024-10-25T09:48:05.957662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 데이터셋을 전처리하여 학습, 검증, 테스트 데이터셋으로 분할하는 함수\n",
    "def get_preprocessed_dataset():\n",
    "    # 학습 및 테스트 데이터 파일 경로 지정\n",
    "    train_data_path = os.path.join(CURRENT_FILE_PATH, \"train.csv\")\n",
    "    test_data_path = os.path.join(CURRENT_FILE_PATH, \"test.csv\")\n",
    "\n",
    "    # 데이터 파일 읽기\n",
    "    train_df = pd.read_csv(train_data_path)\n",
    "    test_df = pd.read_csv(test_data_path)\n",
    "\n",
    "    # 학습 및 테스트 데이터 결합 (전처리를 위해)\n",
    "    all_df = pd.concat([train_df, test_df], sort=False)\n",
    "\n",
    "    # 여러 단계의 전처리 적용\n",
    "    all_df = get_preprocessed_dataset_1(all_df)\n",
    "    all_df = get_preprocessed_dataset_2(all_df)\n",
    "    all_df = get_preprocessed_dataset_3(all_df)\n",
    "    all_df = get_preprocessed_dataset_4(all_df)\n",
    "    all_df = get_preprocessed_dataset_5(all_df)\n",
    "    all_df = get_preprocessed_dataset_6(all_df)\n",
    "\n",
    "    # 학습 데이터와 타겟 분리\n",
    "    train_X = all_df[~all_df[\"Survived\"].isnull()].drop(\"Survived\", axis=1).reset_index(drop=True)\n",
    "    train_y = train_df[\"Survived\"]\n",
    "\n",
    "    # 테스트 데이터 준비\n",
    "    test_X = all_df[all_df[\"Survived\"].isnull()].drop(\"Survived\", axis=1).reset_index(drop=True)\n",
    "\n",
    "    # TitanicDataset 객체 생성하여 학습, 검증, 테스트 데이터셋으로 분할\n",
    "    dataset = TitanicDataset(train_X.values, train_y.values)\n",
    "    train_dataset, validation_dataset = random_split(dataset, [0.8, 0.2])\n",
    "    test_dataset = TitanicTestDataset(test_X.values)\n",
    "\n",
    "    return train_dataset, validation_dataset, test_dataset"
   ],
   "id": "35c3d023e47c6c2e",
   "outputs": [],
   "execution_count": 472
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- `get_preprocessed_dataset_1()` ~ `get_preprocessed_dataset_6()` <br>\n",
    "  각 전처리 함수는 결측치를 채우거나, 범주형 변수를 수치형으로 변환하며, 특정 피처를 추출하여 분석 가능하도록 가공하는 역할을 합니다. 이 과정은 학습에 필요한 중요한 정보를 포함한 피처만을 남기고 불필요한 피처를 제거하는 데 초점을 둡니다. <br>"
   ],
   "id": "dbf7b1f4855402d8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T09:48:06.045709Z",
     "start_time": "2024-10-25T09:48:06.033720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pclass별로 평균 Fare 값을 계산하여 결측치를 채우는 전처리 함수\n",
    "def get_preprocessed_dataset_1(all_df):\n",
    "    # Pclass(등급)별 평균 Fare 계산\n",
    "    Fare_mean = all_df[[\"Pclass\", \"Fare\"]].groupby(\"Pclass\").mean().reset_index()\n",
    "    Fare_mean.columns = [\"Pclass\", \"Fare_mean\"]\n",
    "    # Fare의 결측치를 등급별 평균 Fare 값으로 채움\n",
    "    all_df = pd.merge(all_df, Fare_mean, on=\"Pclass\", how=\"left\")\n",
    "    all_df.loc[(all_df[\"Fare\"].isnull()), \"Fare\"] = all_df[\"Fare_mean\"]\n",
    "\n",
    "    return all_df"
   ],
   "id": "5ce6266aac0bdd7f",
   "outputs": [],
   "execution_count": 473
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- `get_preprocessed_dataset_1()` ~ `get_preprocessed_dataset_6()` <br>\n",
    "  각 전처리 함수는 결측치를 채우거나, 범주형 변수를 수치형으로 변환하며, 특정 피처를 추출하여 분석 가능하도록 가공하는 역할을 합니다. 이 과정은 학습에 필요한 중요한 정보를 포함한 피처만을 남기고 불필요한 피처를 제거하는 데 초점을 둡니다. <br>"
   ],
   "id": "7db0c06cbc7d5ee0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T09:48:06.106243Z",
     "start_time": "2024-10-25T09:48:06.095256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 이름(Name)을 사용하여 성(family_name), 호칭(honorific), 이름(name)을 분리하는 전처리 함수\n",
    "def get_preprocessed_dataset_2(all_df):\n",
    "    # 이름을 쉼표(,)와 점(.)을 기준으로 분리하여 세 개의 컬럼 생성\n",
    "    name_df = all_df[\"Name\"].str.split(\"[,.]\", n=2, expand=True)\n",
    "    name_df.columns = [\"family_name\", \"honorific\", \"name\"]\n",
    "    # 각 문자열을 공백 제거하여 정리\n",
    "    name_df[\"family_name\"] = name_df[\"family_name\"].str.strip()\n",
    "    name_df[\"honorific\"] = name_df[\"honorific\"].str.strip()\n",
    "    name_df[\"name\"] = name_df[\"name\"].str.strip()\n",
    "    # 원래 데이터프레임에 분리된 이름 데이터를 추가\n",
    "    all_df = pd.concat([all_df, name_df], axis=1)\n",
    "\n",
    "    return all_df"
   ],
   "id": "79f18a36740ee5e7",
   "outputs": [],
   "execution_count": 474
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- `get_preprocessed_dataset_1()` ~ `get_preprocessed_dataset_6()` <br>\n",
    "  각 전처리 함수는 결측치를 채우거나, 범주형 변수를 수치형으로 변환하며, 특정 피처를 추출하여 분석 가능하도록 가공하는 역할을 합니다. 이 과정은 학습에 필요한 중요한 정보를 포함한 피처만을 남기고 불필요한 피처를 제거하는 데 초점을 둡니다. <br>"
   ],
   "id": "6f67621ad3051c52"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T09:48:06.136241Z",
     "start_time": "2024-10-25T09:48:06.116243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# honorific(호칭)별로 나이의 중앙값을 계산하여 Age 결측치를 채우는 전처리 함수\n",
    "def get_preprocessed_dataset_3(all_df):\n",
    "    honorific_age_mean = all_df[[\"honorific\", \"Age\"]].groupby(\"honorific\").median().round().reset_index()\n",
    "    honorific_age_mean.columns = [\"honorific\", \"honorific_age_mean\"]\n",
    "    # 호칭별 중앙값으로 Age의 결측치를 채움\n",
    "    all_df = pd.merge(all_df, honorific_age_mean, on=\"honorific\", how=\"left\")\n",
    "    all_df.loc[(all_df[\"Age\"].isnull()), \"Age\"] = all_df[\"honorific_age_mean\"]\n",
    "    # 필요 없는 열 제거\n",
    "    all_df = all_df.drop([\"honorific_age_mean\"], axis=1)\n",
    "\n",
    "    return all_df"
   ],
   "id": "4db2d99401b3142a",
   "outputs": [],
   "execution_count": 475
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- `get_preprocessed_dataset_1()` ~ `get_preprocessed_dataset_6()` <br>\n",
    "  각 전처리 함수는 결측치를 채우거나, 범주형 변수를 수치형으로 변환하며, 특정 피처를 추출하여 분석 가능하도록 가공하는 역할을 합니다. 이 과정은 학습에 필요한 중요한 정보를 포함한 피처만을 남기고 불필요한 피처를 제거하는 데 초점을 둡니다. <br>"
   ],
   "id": "17215d66c82f498"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T09:48:06.181786Z",
     "start_time": "2024-10-25T09:48:06.170286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 가족 수(family_num)와 혼자 탑승 여부(alone)를 나타내는 컬럼 추가 및 불필요한 열 제거\n",
    "def get_preprocessed_dataset_4(all_df):\n",
    "    # 가족 수(family_num) 계산하여 새로운 컬럼에 저장\n",
    "    all_df[\"family_num\"] = all_df[\"Parch\"] + all_df[\"SibSp\"]\n",
    "    # 가족 수가 0이면 혼자 탑승한 것으로 간주하여 alone 컬럼에 1을 할당\n",
    "    all_df.loc[all_df[\"family_num\"] == 0, \"alone\"] = 1\n",
    "    # 가족이 있으면 alone 값을 0으로 설정\n",
    "    all_df[\"alone\"].fillna(0, inplace=True)\n",
    "    # 필요 없는 열(식별자, 이름 등) 삭제\n",
    "    all_df = all_df.drop([\"PassengerId\", \"Name\", \"family_name\", \"name\", \"Ticket\", \"Cabin\"], axis=1)\n",
    "\n",
    "    return all_df"
   ],
   "id": "3cf49404a01229af",
   "outputs": [],
   "execution_count": 476
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- `get_preprocessed_dataset_1()` ~ `get_preprocessed_dataset_6()` <br>\n",
    "  각 전처리 함수는 결측치를 채우거나, 범주형 변수를 수치형으로 변환하며, 특정 피처를 추출하여 분석 가능하도록 가공하는 역할을 합니다. 이 과정은 학습에 필요한 중요한 정보를 포함한 피처만을 남기고 불필요한 피처를 제거하는 데 초점을 둡니다. <br>"
   ],
   "id": "83e4dd28eb395853"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T09:48:06.227293Z",
     "start_time": "2024-10-25T09:48:06.215293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# honorific 값의 개수를 줄여, 자주 등장하지 않는 값들은 \"other\"로 묶음\n",
    "def get_preprocessed_dataset_5(all_df):\n",
    "    # 주요 호칭 이외의 값들을 \"other\"로 변환하여 하나로 묶음\n",
    "    all_df.loc[\n",
    "        ~((all_df[\"honorific\"] == \"Mr\") |\n",
    "          (all_df[\"honorific\"] == \"Miss\") |\n",
    "          (all_df[\"honorific\"] == \"Mrs\") |\n",
    "          (all_df[\"honorific\"] == \"Master\")),\n",
    "        \"honorific\"] = \"other\"\n",
    "    # Embarked(탑승 항구)의 결측치를 \"missing\"으로 채움\n",
    "    all_df[\"Embarked\"].fillna(\"missing\", inplace=True)\n",
    "\n",
    "    return all_df"
   ],
   "id": "70e8044c25566fc2",
   "outputs": [],
   "execution_count": 477
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- `get_preprocessed_dataset_1()` ~ `get_preprocessed_dataset_6()` <br>\n",
    "  각 전처리 함수는 결측치를 채우거나, 범주형 변수를 수치형으로 변환하며, 특정 피처를 추출하여 분석 가능하도록 가공하는 역할을 합니다. 이 과정은 학습에 필요한 중요한 정보를 포함한 피처만을 남기고 불필요한 피처를 제거하는 데 초점을 둡니다. <br>"
   ],
   "id": "72abd3b95340c522"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T09:48:06.272861Z",
     "start_time": "2024-10-25T09:48:06.260834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 범주형 변수들을 LabelEncoder를 사용해 수치형으로 변환하는 함수\n",
    "def get_preprocessed_dataset_6(all_df):\n",
    "    # 데이터프레임에서 문자열 타입인 컬럼들만 추출\n",
    "    category_features = all_df.columns[all_df.dtypes == \"object\"]\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    for category_feature in category_features:\n",
    "        # 각 범주형 변수를 LabelEncoder로 수치형으로 변환\n",
    "        le = LabelEncoder()\n",
    "        if all_df[category_feature].dtypes == \"object\":\n",
    "            le = le.fit(all_df[category_feature])\n",
    "            all_df[category_feature] = le.transform(all_df[category_feature])\n",
    "\n",
    "    return all_df"
   ],
   "id": "8f7068b8f97ebf91",
   "outputs": [],
   "execution_count": 478
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- `get_preprocessed_dataset_1()` ~ `get_preprocessed_dataset_6()` <br>\n",
    "  각 전처리 함수는 결측치를 채우거나, 범주형 변수를 수치형으로 변환하며, 특정 피처를 추출하여 분석 가능하도록 가공하는 역할을 합니다. 이 과정은 학습에 필요한 중요한 정보를 포함한 피처만을 남기고 불필요한 피처를 제거하는 데 초점을 둡니다. <br>"
   ],
   "id": "7457aea3b2473b5d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T09:48:06.318385Z",
     "start_time": "2024-10-25T09:48:06.307378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "\n",
    "# 신경망 모델 정의\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, n_input, n_output):\n",
    "        super().__init__()\n",
    "        # 신경망 구조 정의 (은닉층 2개, 각 층 30개의 유닛)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 30),  # 입력층 -> 첫 번째 은닉층\n",
    "            nn.ReLU(),               # 활성화 함수로 ReLU 사용\n",
    "            nn.Linear(30, 30),       # 첫 번째 은닉층 -> 두 번째 은닉층\n",
    "            nn.ReLU(),               # ReLU 활성화 함수\n",
    "            nn.Linear(30, n_output), # 두 번째 은닉층 -> 출력층\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 입력 x를 모델에 통과시켜 최종 출력값 반환\n",
    "        x = self.model(x)\n",
    "        return x"
   ],
   "id": "65e9fe6b1aa76643",
   "outputs": [],
   "execution_count": 479
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- `MyModel` <br>\n",
    "  신경망 모델 구조를 정의하며, 입력층, 두 개의 은닉층, 출력층으로 구성되어 있습니다. 각 은닉층은 `ReLU` 활성화 함수가 적용되며, 모델에 입력 데이터를 통과시켜 분류 확률을 산출합니다. <br>"
   ],
   "id": "5c6bcc89575427b8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T09:48:06.379268Z",
     "start_time": "2024-10-25T09:48:06.352928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 테스트 함수: 테스트 데이터셋을 통해 모델의 예측을 출력\n",
    "def test(test_data_loader):\n",
    "    print(\"[TEST]\")\n",
    "    # 테스트 데이터에서 첫 번째 배치를 가져옴\n",
    "    batch = next(iter(test_data_loader))\n",
    "    print(\"{0}\".format(batch['input'].shape))\n",
    "    # 테스트를 위한 모델 생성 (입력 노드 11개, 출력 노드 2개)\n",
    "    my_model = MyModel(n_input=11, n_output=2)\n",
    "    # 모델을 통해 배치의 입력 데이터를 예측\n",
    "    output_batch = my_model(batch['input'])\n",
    "    # 출력의 각 샘플에서 가장 높은 확률의 클래스를 예측값으로 선택\n",
    "    prediction_batch = torch.argmax(output_batch, dim=1)\n",
    "    # 예측 결과 출력 (테스트 데이터의 인덱스와 예측값)\n",
    "    for idx, prediction in enumerate(prediction_batch, start=892):\n",
    "        print(idx, prediction.item())"
   ],
   "id": "ec5f8e04c4785372",
   "outputs": [],
   "execution_count": 480
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- `test()` <br>\n",
    "  테스트 데이터셋에 대해 모델의 예측 결과를 출력합니다. `DataLoader`를 통해 배치를 가져와 각 샘플에 대해 모델의 예측 값을 확인하고, 테스트 데이터의 각 인덱스에 대해 최종 예측을 출력하여 성능을 평가할 수 있습니다. <br>"
   ],
   "id": "e0d7130d8c945983"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T09:48:09.538242Z",
     "start_time": "2024-10-25T09:48:06.425359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 메인 함수\n",
    "if __name__ == \"__main__\":\n",
    "    # 전처리된 데이터셋을 가져와 학습, 검증, 테스트 데이터셋으로 분리\n",
    "    train_dataset, validation_dataset, test_dataset = get_preprocessed_dataset()\n",
    "\n",
    "    # 데이터셋 크기 출력\n",
    "    print(\"train_dataset: {0}, validation_dataset.shape: {1}, test_dataset: {2}\".format(\n",
    "        len(train_dataset), len(validation_dataset), len(test_dataset)\n",
    "    ))\n",
    "\n",
    "    # DataLoader를 사용해 학습, 검증, 테스트 데이터 로드\n",
    "    train_data_loader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\n",
    "    validation_data_loader = DataLoader(dataset=validation_dataset, batch_size=16, shuffle=True)\n",
    "    test_data_loader = DataLoader(dataset=test_dataset, batch_size=len(test_dataset))\n",
    "\n",
    "    # 학습 데이터 로드 확인\n",
    "    print(\"[TRAIN]\")\n",
    "    for idx, batch in enumerate(train_data_loader):\n",
    "        print(\"{0} - {1}: {2}\".format(idx, batch['input'].shape, batch['target'].shape))\n",
    "\n",
    "    # 검증 데이터 로드 확인\n",
    "    print(\"[VALIDATION]\")\n",
    "    for idx, batch in enumerate(validation_data_loader):\n",
    "        print(\"{0} - {1}: {2}\".format(idx, batch['input'].shape, batch['target'].shape))\n",
    "\n",
    "    # 테스트 함수 호출하여 테스트 데이터의 예측 결과 확인\n",
    "    test(test_data_loader)"
   ],
   "id": "9248d4c6440d1f36",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alstj\\AppData\\Local\\Temp\\ipykernel_16408\\928423758.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df[\"alone\"].fillna(0, inplace=True)\n",
      "C:\\Users\\alstj\\AppData\\Local\\Temp\\ipykernel_16408\\377400784.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df[\"Embarked\"].fillna(\"missing\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset: 713, validation_dataset.shape: 178, test_dataset: 418\n",
      "[TRAIN]\n",
      "0 - torch.Size([16, 11]): torch.Size([16])\n",
      "1 - torch.Size([16, 11]): torch.Size([16])\n",
      "2 - torch.Size([16, 11]): torch.Size([16])\n",
      "3 - torch.Size([16, 11]): torch.Size([16])\n",
      "4 - torch.Size([16, 11]): torch.Size([16])\n",
      "5 - torch.Size([16, 11]): torch.Size([16])\n",
      "6 - torch.Size([16, 11]): torch.Size([16])\n",
      "7 - torch.Size([16, 11]): torch.Size([16])\n",
      "8 - torch.Size([16, 11]): torch.Size([16])\n",
      "9 - torch.Size([16, 11]): torch.Size([16])\n",
      "10 - torch.Size([16, 11]): torch.Size([16])\n",
      "11 - torch.Size([16, 11]): torch.Size([16])\n",
      "12 - torch.Size([16, 11]): torch.Size([16])\n",
      "13 - torch.Size([16, 11]): torch.Size([16])\n",
      "14 - torch.Size([16, 11]): torch.Size([16])\n",
      "15 - torch.Size([16, 11]): torch.Size([16])\n",
      "16 - torch.Size([16, 11]): torch.Size([16])\n",
      "17 - torch.Size([16, 11]): torch.Size([16])\n",
      "18 - torch.Size([16, 11]): torch.Size([16])\n",
      "19 - torch.Size([16, 11]): torch.Size([16])\n",
      "20 - torch.Size([16, 11]): torch.Size([16])\n",
      "21 - torch.Size([16, 11]): torch.Size([16])\n",
      "22 - torch.Size([16, 11]): torch.Size([16])\n",
      "23 - torch.Size([16, 11]): torch.Size([16])\n",
      "24 - torch.Size([16, 11]): torch.Size([16])\n",
      "25 - torch.Size([16, 11]): torch.Size([16])\n",
      "26 - torch.Size([16, 11]): torch.Size([16])\n",
      "27 - torch.Size([16, 11]): torch.Size([16])\n",
      "28 - torch.Size([16, 11]): torch.Size([16])\n",
      "29 - torch.Size([16, 11]): torch.Size([16])\n",
      "30 - torch.Size([16, 11]): torch.Size([16])\n",
      "31 - torch.Size([16, 11]): torch.Size([16])\n",
      "32 - torch.Size([16, 11]): torch.Size([16])\n",
      "33 - torch.Size([16, 11]): torch.Size([16])\n",
      "34 - torch.Size([16, 11]): torch.Size([16])\n",
      "35 - torch.Size([16, 11]): torch.Size([16])\n",
      "36 - torch.Size([16, 11]): torch.Size([16])\n",
      "37 - torch.Size([16, 11]): torch.Size([16])\n",
      "38 - torch.Size([16, 11]): torch.Size([16])\n",
      "39 - torch.Size([16, 11]): torch.Size([16])\n",
      "40 - torch.Size([16, 11]): torch.Size([16])\n",
      "41 - torch.Size([16, 11]): torch.Size([16])\n",
      "42 - torch.Size([16, 11]): torch.Size([16])\n",
      "43 - torch.Size([16, 11]): torch.Size([16])\n",
      "44 - torch.Size([9, 11]): torch.Size([9])\n",
      "[VALIDATION]\n",
      "0 - torch.Size([16, 11]): torch.Size([16])\n",
      "1 - torch.Size([16, 11]): torch.Size([16])\n",
      "2 - torch.Size([16, 11]): torch.Size([16])\n",
      "3 - torch.Size([16, 11]): torch.Size([16])\n",
      "4 - torch.Size([16, 11]): torch.Size([16])\n",
      "5 - torch.Size([16, 11]): torch.Size([16])\n",
      "6 - torch.Size([16, 11]): torch.Size([16])\n",
      "7 - torch.Size([16, 11]): torch.Size([16])\n",
      "8 - torch.Size([16, 11]): torch.Size([16])\n",
      "9 - torch.Size([16, 11]): torch.Size([16])\n",
      "10 - torch.Size([16, 11]): torch.Size([16])\n",
      "11 - torch.Size([2, 11]): torch.Size([2])\n",
      "[TEST]\n",
      "torch.Size([418, 11])\n",
      "892 0\n",
      "893 1\n",
      "894 1\n",
      "895 0\n",
      "896 0\n",
      "897 0\n",
      "898 0\n",
      "899 0\n",
      "900 0\n",
      "901 0\n",
      "902 0\n",
      "903 0\n",
      "904 0\n",
      "905 0\n",
      "906 0\n",
      "907 0\n",
      "908 0\n",
      "909 0\n",
      "910 0\n",
      "911 1\n",
      "912 0\n",
      "913 0\n",
      "914 0\n",
      "915 0\n",
      "916 0\n",
      "917 0\n",
      "918 0\n",
      "919 0\n",
      "920 0\n",
      "921 0\n",
      "922 0\n",
      "923 0\n",
      "924 0\n",
      "925 0\n",
      "926 0\n",
      "927 0\n",
      "928 0\n",
      "929 0\n",
      "930 0\n",
      "931 0\n",
      "932 0\n",
      "933 0\n",
      "934 1\n",
      "935 0\n",
      "936 0\n",
      "937 0\n",
      "938 0\n",
      "939 0\n",
      "940 0\n",
      "941 0\n",
      "942 0\n",
      "943 0\n",
      "944 0\n",
      "945 0\n",
      "946 0\n",
      "947 0\n",
      "948 0\n",
      "949 0\n",
      "950 0\n",
      "951 0\n",
      "952 0\n",
      "953 0\n",
      "954 0\n",
      "955 0\n",
      "956 0\n",
      "957 0\n",
      "958 0\n",
      "959 0\n",
      "960 0\n",
      "961 0\n",
      "962 0\n",
      "963 0\n",
      "964 0\n",
      "965 0\n",
      "966 0\n",
      "967 0\n",
      "968 0\n",
      "969 0\n",
      "970 0\n",
      "971 0\n",
      "972 0\n",
      "973 0\n",
      "974 0\n",
      "975 0\n",
      "976 0\n",
      "977 0\n",
      "978 0\n",
      "979 0\n",
      "980 0\n",
      "981 0\n",
      "982 0\n",
      "983 0\n",
      "984 0\n",
      "985 0\n",
      "986 0\n",
      "987 0\n",
      "988 0\n",
      "989 0\n",
      "990 0\n",
      "991 0\n",
      "992 0\n",
      "993 0\n",
      "994 0\n",
      "995 0\n",
      "996 0\n",
      "997 0\n",
      "998 0\n",
      "999 0\n",
      "1000 0\n",
      "1001 0\n",
      "1002 0\n",
      "1003 0\n",
      "1004 0\n",
      "1005 0\n",
      "1006 0\n",
      "1007 0\n",
      "1008 0\n",
      "1009 0\n",
      "1010 0\n",
      "1011 0\n",
      "1012 0\n",
      "1013 0\n",
      "1014 0\n",
      "1015 0\n",
      "1016 0\n",
      "1017 0\n",
      "1018 0\n",
      "1019 0\n",
      "1020 0\n",
      "1021 0\n",
      "1022 0\n",
      "1023 0\n",
      "1024 0\n",
      "1025 0\n",
      "1026 1\n",
      "1027 0\n",
      "1028 0\n",
      "1029 0\n",
      "1030 0\n",
      "1031 0\n",
      "1032 0\n",
      "1033 0\n",
      "1034 0\n",
      "1035 0\n",
      "1036 0\n",
      "1037 0\n",
      "1038 0\n",
      "1039 0\n",
      "1040 0\n",
      "1041 0\n",
      "1042 0\n",
      "1043 0\n",
      "1044 1\n",
      "1045 0\n",
      "1046 0\n",
      "1047 0\n",
      "1048 0\n",
      "1049 0\n",
      "1050 0\n",
      "1051 0\n",
      "1052 0\n",
      "1053 0\n",
      "1054 0\n",
      "1055 0\n",
      "1056 0\n",
      "1057 0\n",
      "1058 0\n",
      "1059 0\n",
      "1060 0\n",
      "1061 0\n",
      "1062 0\n",
      "1063 0\n",
      "1064 0\n",
      "1065 0\n",
      "1066 0\n",
      "1067 0\n",
      "1068 0\n",
      "1069 0\n",
      "1070 0\n",
      "1071 0\n",
      "1072 0\n",
      "1073 0\n",
      "1074 0\n",
      "1075 0\n",
      "1076 0\n",
      "1077 0\n",
      "1078 0\n",
      "1079 0\n",
      "1080 0\n",
      "1081 0\n",
      "1082 0\n",
      "1083 0\n",
      "1084 0\n",
      "1085 0\n",
      "1086 0\n",
      "1087 0\n",
      "1088 0\n",
      "1089 0\n",
      "1090 0\n",
      "1091 0\n",
      "1092 0\n",
      "1093 0\n",
      "1094 0\n",
      "1095 0\n",
      "1096 0\n",
      "1097 0\n",
      "1098 1\n",
      "1099 0\n",
      "1100 0\n",
      "1101 0\n",
      "1102 0\n",
      "1103 0\n",
      "1104 0\n",
      "1105 0\n",
      "1106 0\n",
      "1107 0\n",
      "1108 0\n",
      "1109 0\n",
      "1110 0\n",
      "1111 0\n",
      "1112 0\n",
      "1113 0\n",
      "1114 0\n",
      "1115 0\n",
      "1116 0\n",
      "1117 0\n",
      "1118 0\n",
      "1119 0\n",
      "1120 0\n",
      "1121 0\n",
      "1122 0\n",
      "1123 0\n",
      "1124 0\n",
      "1125 0\n",
      "1126 0\n",
      "1127 0\n",
      "1128 0\n",
      "1129 0\n",
      "1130 0\n",
      "1131 0\n",
      "1132 0\n",
      "1133 0\n",
      "1134 0\n",
      "1135 0\n",
      "1136 0\n",
      "1137 0\n",
      "1138 0\n",
      "1139 0\n",
      "1140 0\n",
      "1141 0\n",
      "1142 0\n",
      "1143 0\n",
      "1144 0\n",
      "1145 0\n",
      "1146 0\n",
      "1147 0\n",
      "1148 0\n",
      "1149 0\n",
      "1150 0\n",
      "1151 0\n",
      "1152 0\n",
      "1153 0\n",
      "1154 0\n",
      "1155 0\n",
      "1156 0\n",
      "1157 0\n",
      "1158 0\n",
      "1159 0\n",
      "1160 0\n",
      "1161 0\n",
      "1162 0\n",
      "1163 0\n",
      "1164 0\n",
      "1165 0\n",
      "1166 0\n",
      "1167 0\n",
      "1168 0\n",
      "1169 0\n",
      "1170 0\n",
      "1171 0\n",
      "1172 0\n",
      "1173 0\n",
      "1174 0\n",
      "1175 0\n",
      "1176 0\n",
      "1177 0\n",
      "1178 0\n",
      "1179 0\n",
      "1180 0\n",
      "1181 0\n",
      "1182 0\n",
      "1183 0\n",
      "1184 0\n",
      "1185 0\n",
      "1186 0\n",
      "1187 0\n",
      "1188 0\n",
      "1189 0\n",
      "1190 0\n",
      "1191 0\n",
      "1192 0\n",
      "1193 0\n",
      "1194 0\n",
      "1195 0\n",
      "1196 0\n",
      "1197 0\n",
      "1198 0\n",
      "1199 0\n",
      "1200 0\n",
      "1201 0\n",
      "1202 0\n",
      "1203 0\n",
      "1204 0\n",
      "1205 1\n",
      "1206 0\n",
      "1207 0\n",
      "1208 0\n",
      "1209 0\n",
      "1210 0\n",
      "1211 0\n",
      "1212 0\n",
      "1213 0\n",
      "1214 0\n",
      "1215 0\n",
      "1216 0\n",
      "1217 0\n",
      "1218 0\n",
      "1219 0\n",
      "1220 0\n",
      "1221 0\n",
      "1222 0\n",
      "1223 0\n",
      "1224 0\n",
      "1225 0\n",
      "1226 0\n",
      "1227 0\n",
      "1228 0\n",
      "1229 1\n",
      "1230 0\n",
      "1231 0\n",
      "1232 0\n",
      "1233 0\n",
      "1234 0\n",
      "1235 0\n",
      "1236 0\n",
      "1237 0\n",
      "1238 0\n",
      "1239 1\n",
      "1240 0\n",
      "1241 0\n",
      "1242 0\n",
      "1243 0\n",
      "1244 0\n",
      "1245 0\n",
      "1246 0\n",
      "1247 0\n",
      "1248 0\n",
      "1249 0\n",
      "1250 0\n",
      "1251 0\n",
      "1252 0\n",
      "1253 0\n",
      "1254 0\n",
      "1255 0\n",
      "1256 0\n",
      "1257 0\n",
      "1258 0\n",
      "1259 0\n",
      "1260 0\n",
      "1261 0\n",
      "1262 0\n",
      "1263 0\n",
      "1264 0\n",
      "1265 0\n",
      "1266 0\n",
      "1267 0\n",
      "1268 0\n",
      "1269 0\n",
      "1270 0\n",
      "1271 0\n",
      "1272 0\n",
      "1273 0\n",
      "1274 0\n",
      "1275 0\n",
      "1276 0\n",
      "1277 0\n",
      "1278 0\n",
      "1279 0\n",
      "1280 0\n",
      "1281 0\n",
      "1282 0\n",
      "1283 0\n",
      "1284 0\n",
      "1285 0\n",
      "1286 0\n",
      "1287 0\n",
      "1288 0\n",
      "1289 0\n",
      "1290 0\n",
      "1291 0\n",
      "1292 0\n",
      "1293 0\n",
      "1294 0\n",
      "1295 0\n",
      "1296 0\n",
      "1297 0\n",
      "1298 0\n",
      "1299 0\n",
      "1300 0\n",
      "1301 0\n",
      "1302 0\n",
      "1303 0\n",
      "1304 0\n",
      "1305 0\n",
      "1306 0\n",
      "1307 1\n",
      "1308 0\n",
      "1309 0\n"
     ]
    }
   ],
   "execution_count": 481
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- `main()` <br>\n",
    "  전처리된 데이터셋을 불러와 학습, 검증, 테스트 `DataLoader`를 구성하고, 데이터 로드가 제대로 되었는지 확인합니다. 또한, 테스트 함수 호출을 통해 테스트 데이터셋의 예측 결과를 확인하여 전체 파이프라인의 정확성을 점검할 수 있습니다. <br>"
   ],
   "id": "6b45238033901265"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T09:48:09.643882Z",
     "start_time": "2024-10-25T09:48:09.572284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "import argparse\n",
    "import pandas as pd\n",
    "\n",
    "# 타이타닉 데이터셋 함수 호출: 데이터셋 로드 및 전처리를 통해 학습, 검증, 테스트 세트 반환\n",
    "train_dataset, validation_dataset, test_dataset = get_preprocessed_dataset()\n",
    "\n",
    "\n",
    "# 데이터 로더 정의 함수: 배치 사이즈에 맞춰 데이터셋을 로드하는 DataLoader를 반환\n",
    "def get_data():\n",
    "    train_data_loader = DataLoader(dataset=train_dataset, batch_size=wandb.config.batch_size, shuffle=True)\n",
    "    validation_data_loader = DataLoader(dataset=validation_dataset, batch_size=wandb.config.batch_size)\n",
    "    test_data_loader = DataLoader(dataset=test_dataset, batch_size=wandb.config.batch_size, shuffle=False)\n",
    "    return train_data_loader, validation_data_loader, test_data_loader\n"
   ],
   "id": "3ee6664a2ecb435c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alstj\\AppData\\Local\\Temp\\ipykernel_16408\\928423758.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df[\"alone\"].fillna(0, inplace=True)\n",
      "C:\\Users\\alstj\\AppData\\Local\\Temp\\ipykernel_16408\\377400784.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df[\"Embarked\"].fillna(\"missing\", inplace=True)\n"
     ]
    }
   ],
   "execution_count": 482
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "get_preprocessed_dataset()<br>\n",
    "고찰: 타이타닉 데이터셋의 전처리를 수행하는 핵심 함수입니다. 데이터를 학습, 검증, 테스트 세트로 나누어 모델이 각각의 데이터에 대해 적절히 학습하고 일반화되도록 돕습니다. 전처리된 데이터는 모델 성능에 큰 영향을 미치므로 데이터 정제의 중요성을 강조하는 함수입니다.<br>\n",
    "get_data()<br>\n",
    "고찰: DataLoader 객체를 생성하여 모델 훈련 시 효율적인 데이터 로드를 가능하게 합니다. 훈련과 검증을 위한 배치 사이즈와 셔플 여부를 설정해 데이터 로딩을 최적화하며, 이 함수는 반복 학습과 배치 단위 처리의 중요성을 나타냅니다."
   ],
   "id": "28391a974942cda1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T09:48:09.749417Z",
     "start_time": "2024-10-25T09:48:09.728418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 모델 정의 클래스: 입력 크기, 출력 크기, 활성화 함수를 받아 모델 생성\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, n_input, n_output, activation_fn):\n",
    "        super().__init__()\n",
    "        # 두 개의 은닉층과 출력층을 포함한 신경망 구조 정의\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, wandb.config.n_hidden_unit_list[0]),  # 첫 번째 은닉층\n",
    "            activation_fn,  # 첫 번째 활성화 함수\n",
    "            nn.Linear(wandb.config.n_hidden_unit_list[0], wandb.config.n_hidden_unit_list[1]),  # 두 번째 은닉층\n",
    "            activation_fn,  # 두 번째 활성화 함수\n",
    "            nn.Linear(wandb.config.n_hidden_unit_list[1], n_output),  # 출력층\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 모델에 입력값 x를 통과시켜 출력값 반환\n",
    "        return self.model(x)"
   ],
   "id": "acbfcd8eb27dfad4",
   "outputs": [],
   "execution_count": 483
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "MyModel<br>\n",
    "고찰: 신경망 모델 구조를 정의하는 클래스입니다. 이 클래스는 활성화 함수를 인자로 받아 유연하게 구성 가능하며, 층의 수와 활성화 함수는 모델의 학습 성능에 영향을 미칩니다. 모델의 구조는 학습 성능과 모델 일반화에 중대한 영향을 미치는 요소로, 이 클래스를 통해 실험적인 조정이 가능합니다."
   ],
   "id": "24db6cc07bbad68c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T09:48:09.839560Z",
     "start_time": "2024-10-25T09:48:09.818545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 모델과 옵티마이저 반환 함수: 활성화 함수를 인자로 받아 모델과 Adam 옵티마이저 반환\n",
    "def get_model_and_optimizer(activation_fn):\n",
    "    model = MyModel(n_input=11, n_output=2, activation_fn=activation_fn)  # 입력 크기 및 출력 크기 지정\n",
    "    optimizer = optim.Adam(model.parameters(), lr=wandb.config.learning_rate)  # Adam 옵티마이저 설정\n",
    "    return model, optimizer\n"
   ],
   "id": "68ba377a0fda530f",
   "outputs": [],
   "execution_count": 484
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "get_model_and_optimizer() : 모델과 옵티마이저를 구성하여 빠르고 안정적인 수렴을 도모합니다. <br> ",
   "id": "89f95fcd0f9d6052"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T09:48:09.900651Z",
     "start_time": "2024-10-25T09:48:09.873590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 훈련 함수: 모델 훈련과 검증 과정을 진행하며 검증 손실이 가장 낮은 모델을 반환\n",
    "def training_loop(model, optimizer, train_data_loader, validation_data_loader):\n",
    "    loss_fn = nn.CrossEntropyLoss()  # 손실 함수로 CrossEntropy 사용 (분류 문제)\n",
    "    n_epochs = wandb.config.epochs\n",
    "    best_validation_loss = float(\"inf\")  # 최적의 검증 손실 초기화\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        # 모델 훈련\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for train_batch in train_data_loader:\n",
    "            input, target = train_batch['input'], train_batch['target']  # 배치에서 입력과 타겟 추출\n",
    "            output = model(input)  # 모델 출력값\n",
    "            loss = loss_fn(output, target)  # 손실 계산\n",
    "            train_loss += loss.item()  # 총 손실 값에 누적\n",
    "\n",
    "            optimizer.zero_grad()  # 기울기 초기화\n",
    "            loss.backward()  # 역전파 수행\n",
    "            optimizer.step()  # 가중치 업데이트\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_data_loader)  # 평균 훈련 손실 계산\n",
    "\n",
    "        # 모델 검증\n",
    "        model.eval()\n",
    "        validation_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for validation_batch in validation_data_loader:\n",
    "                input, target = validation_batch['input'], validation_batch['target']\n",
    "                output = model(input)\n",
    "                loss = loss_fn(output, target)\n",
    "                validation_loss += loss.item()\n",
    "\n",
    "        avg_validation_loss = validation_loss / len(validation_data_loader)  # 평균 검증 손실 계산\n",
    "        if avg_validation_loss < best_validation_loss:\n",
    "            best_validation_loss = avg_validation_loss\n",
    "            best_model_state = model.state_dict()  # 최적의 모델 저장\n",
    "\n",
    "        # wandb 로그 기록\n",
    "        wandb.log({\n",
    "            \"Epoch\": epoch,\n",
    "            \"Training Loss\": avg_train_loss,\n",
    "            \"Validation Loss\": avg_validation_loss\n",
    "        })\n",
    "\n",
    "        # 매 100 에폭마다 손실 출력\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_validation_loss:.4f}\")\n",
    "\n",
    "    return best_model_state, best_validation_loss  # 최적 모델과 손실 반환"
   ],
   "id": "ee08c67c815dba0c",
   "outputs": [],
   "execution_count": 485
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "training_loop() : 에포크 동안 훈련과 검증을 반복해 최적의 모델을 탐색하며, 손실 기록을 통해 학습 상태를 추적합니다. <br> ",
   "id": "b935fc5da1c8fc5a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T09:48:09.960977Z",
     "start_time": "2024-10-25T09:48:09.936624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 테스트 함수: 테스트 데이터에 대해 예측하고 결과를 CSV 파일로 저장\n",
    "def test_model(model, test_data_loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_data_loader:\n",
    "            inputs = batch['input']\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)  # 가장 높은 확률의 클래스 선택\n",
    "            predictions.extend(predicted.tolist())\n",
    "\n",
    "    # 예측 결과를 submission.csv 파일로 저장\n",
    "    submission = pd.DataFrame({\n",
    "        \"PassengerId\": range(892, 892 + len(predictions)),\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "    submission.to_csv(\"submission.csv\", index=False)\n",
    "    print(\"submission.csv has been created.\")"
   ],
   "id": "585942651ade303d",
   "outputs": [],
   "execution_count": 486
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "test_model() : 최적 모델을 사용해 테스트 데이터에서 예측을 수행, 결과를 CSV 파일로 저장하여 모델 성능 평가에 활용합니다. <br>",
   "id": "c8d09579ff1dc695"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T09:48:10.021480Z",
     "start_time": "2024-10-25T09:48:09.995498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 메인 함수: 모델 훈련 및 검증 과정을 각 활성화 함수로 수행하여 최적의 모델 선택\n",
    "def main(args):\n",
    "    config = {\n",
    "        'epochs': args.epochs,\n",
    "        'batch_size': args.batch_size,\n",
    "        'learning_rate': 1e-3,\n",
    "        'n_hidden_unit_list': [20, 20],\n",
    "    }\n",
    "\n",
    "    # wandb 초기화 설정\n",
    "    wandb.init(\n",
    "        mode=\"online\" if args.wandb else \"disabled\",\n",
    "        project=\"titanic_training\",\n",
    "        name=f\"Run_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n",
    "        config=config\n",
    "    )\n",
    "\n",
    "    # 데이터 로더 호출\n",
    "    train_data_loader, validation_data_loader, test_data_loader = get_data()\n",
    "\n",
    "    # 여러 활성화 함수에 대한 검증\n",
    "    activation_functions = {\n",
    "        \"ELU\": nn.ELU(),\n",
    "        \"ReLU\": nn.ReLU(),\n",
    "        \"LeakyReLU\": nn.LeakyReLU(0.01),\n",
    "        \"PReLU\": nn.PReLU()\n",
    "    }\n",
    "\n",
    "    best_validation_loss = float(\"inf\")  # 최적의 검증 손실 초기화\n",
    "    best_activation_fn = None  # 최적의 활성화 함수 초기화\n",
    "\n",
    "    for name, activation_fn in activation_functions.items():\n",
    "        print(f\"Training with {name} activation function.\")\n",
    "        model, optimizer = get_model_and_optimizer(activation_fn)\n",
    "        model_state, validation_loss = training_loop(model, optimizer, train_data_loader, validation_data_loader)\n",
    "\n",
    "        print(f\"{name} Validation Loss: {validation_loss:.4f}\")\n",
    "        if validation_loss < best_validation_loss:\n",
    "            best_validation_loss = validation_loss\n",
    "            best_activation_fn = activation_fn\n",
    "            best_model_state = model_state\n",
    "\n",
    "    print(f\"Best Activation Function: {best_activation_fn} with Validation Loss: {best_validation_loss:.4f}\")\n",
    "\n",
    "    # 최적 활성화 함수로 모델 재구성 및 테스트 예측 수행\n",
    "    final_model = MyModel(n_input=11, n_output=2, activation_fn=best_activation_fn)\n",
    "    final_model.load_state_dict(best_model_state)\n",
    "    test_model(final_model, test_data_loader)\n",
    "    wandb.finish()"
   ],
   "id": "4f6e42c6c540efdd",
   "outputs": [],
   "execution_count": 487
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "main() : 활성화 함수별로 모델 훈련 및 검증을 수행, 최적의 활성화 함수를 선택해 테스트 데이터에서 최종 평가를 진행합니다. <br>  ",
   "id": "7bffb4444b97dc31"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T09:50:15.674870Z",
     "start_time": "2024-10-25T09:48:10.055486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--wandb\", action=argparse.BooleanOptionalAction, default=True, help=\"Use wandb logging\")\n",
    "    parser.add_argument(\"-b\", \"--batch_size\", type=int, default=100, help=\"Batch size (int, default: 100)\")\n",
    "    parser.add_argument(\"-e\", \"--epochs\", type=int, default=1000, help=\"Number of training epochs (int, default: 1000)\")\n",
    "    args = parser.parse_args(args=[])\n",
    "    main(args)"
   ],
   "id": "699994adf8651de0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Finishing last run (ID:hbbpbr11) before initializing another..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▂▃▄▄▅▆▆▇█▁▂▃▃▄▅▅▆▇▇█▁▂▃▃▄▅▆▆▇█▁▂▂▃▄▅▅▆</td></tr><tr><td>Training Loss</td><td>▆▄▃▂▂▃▂▂▂▂▁▅▄▃▂▂▂▂▂▂▁▁▅▃▃▃▂▁▂▂▂▁█▄▄▄▄▄▄▄</td></tr><tr><td>Validation Loss</td><td>▂▁▁▂▂▃▃▅▅▅▆▂▂▂▃▃▃▄▅▅▆▇▂▂▃▄▅▅▆▇██▃▁▂▂▁▃▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>722</td></tr><tr><td>Training Loss</td><td>0.32363</td></tr><tr><td>Validation Loss</td><td>0.55731</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Run_2024-10-25_18-45-40</strong> at: <a href='https://wandb.ai/alstjr7141-korea-university-of-technology-and-education/titanic_training/runs/hbbpbr11' target=\"_blank\">https://wandb.ai/alstjr7141-korea-university-of-technology-and-education/titanic_training/runs/hbbpbr11</a><br/> View project at: <a href='https://wandb.ai/alstjr7141-korea-university-of-technology-and-education/titanic_training' target=\"_blank\">https://wandb.ai/alstjr7141-korea-university-of-technology-and-education/titanic_training</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241025_184540-hbbpbr11\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Successfully finished last run (ID:hbbpbr11). Initializing new run:<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\alstj\\Desktop\\대학교\\3학년\\2학기\\딥러닝\\git\\deep\\link_dl_HomeWork\\_02_homeworks\\HW_2\\wandb\\run-20241025_184810-7mrje86e</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alstjr7141-korea-university-of-technology-and-education/titanic_training/runs/7mrje86e' target=\"_blank\">Run_2024-10-25_18-48-10</a></strong> to <a href='https://wandb.ai/alstjr7141-korea-university-of-technology-and-education/titanic_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/alstjr7141-korea-university-of-technology-and-education/titanic_training' target=\"_blank\">https://wandb.ai/alstjr7141-korea-university-of-technology-and-education/titanic_training</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/alstjr7141-korea-university-of-technology-and-education/titanic_training/runs/7mrje86e' target=\"_blank\">https://wandb.ai/alstjr7141-korea-university-of-technology-and-education/titanic_training/runs/7mrje86e</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with ELU activation function.\n",
      "Epoch 100, Training Loss: 0.3985, Validation Loss: 0.4880\n",
      "Epoch 200, Training Loss: 0.3609, Validation Loss: 0.4710\n",
      "Epoch 300, Training Loss: 0.3435, Validation Loss: 0.4675\n",
      "Epoch 400, Training Loss: 0.3357, Validation Loss: 0.5185\n",
      "Epoch 500, Training Loss: 0.3278, Validation Loss: 0.5512\n",
      "Epoch 600, Training Loss: 0.3078, Validation Loss: 0.5560\n",
      "Epoch 700, Training Loss: 0.2979, Validation Loss: 0.5560\n",
      "Epoch 800, Training Loss: 0.2986, Validation Loss: 0.5750\n",
      "Epoch 900, Training Loss: 0.2897, Validation Loss: 0.6479\n",
      "Epoch 1000, Training Loss: 0.2921, Validation Loss: 0.6230\n",
      "ELU Validation Loss: 0.4522\n",
      "Training with ReLU activation function.\n",
      "Epoch 100, Training Loss: 0.4457, Validation Loss: 0.5076\n",
      "Epoch 200, Training Loss: 0.3816, Validation Loss: 0.5056\n",
      "Epoch 300, Training Loss: 0.3635, Validation Loss: 0.4609\n",
      "Epoch 400, Training Loss: 0.3914, Validation Loss: 0.4733\n",
      "Epoch 500, Training Loss: 0.3589, Validation Loss: 0.5005\n",
      "Epoch 600, Training Loss: 0.3322, Validation Loss: 0.4972\n",
      "Epoch 700, Training Loss: 0.3362, Validation Loss: 0.4964\n",
      "Epoch 800, Training Loss: 0.3414, Validation Loss: 0.5434\n",
      "Epoch 900, Training Loss: 0.3711, Validation Loss: 0.4752\n",
      "Epoch 1000, Training Loss: 0.3310, Validation Loss: 0.5238\n",
      "ReLU Validation Loss: 0.4459\n",
      "Training with LeakyReLU activation function.\n",
      "Epoch 100, Training Loss: 0.3916, Validation Loss: 0.5113\n",
      "Epoch 200, Training Loss: 0.3684, Validation Loss: 0.5037\n",
      "Epoch 300, Training Loss: 0.3665, Validation Loss: 0.5004\n",
      "Epoch 400, Training Loss: 0.3964, Validation Loss: 0.5211\n",
      "Epoch 500, Training Loss: 0.3468, Validation Loss: 0.5109\n",
      "Epoch 600, Training Loss: 0.3306, Validation Loss: 0.5529\n",
      "Epoch 700, Training Loss: 0.3192, Validation Loss: 0.5874\n",
      "Epoch 800, Training Loss: 0.3535, Validation Loss: 0.6191\n",
      "Epoch 900, Training Loss: 0.2973, Validation Loss: 0.6514\n",
      "Epoch 1000, Training Loss: 0.3000, Validation Loss: 0.6885\n",
      "LeakyReLU Validation Loss: 0.4683\n",
      "Training with PReLU activation function.\n",
      "Epoch 100, Training Loss: 0.4366, Validation Loss: 0.5342\n",
      "Epoch 200, Training Loss: 0.3862, Validation Loss: 0.4694\n",
      "Epoch 300, Training Loss: 0.3780, Validation Loss: 0.4768\n",
      "Epoch 400, Training Loss: 0.3710, Validation Loss: 0.4659\n",
      "Epoch 500, Training Loss: 0.3286, Validation Loss: 0.4987\n",
      "Epoch 600, Training Loss: 0.3675, Validation Loss: 0.5111\n",
      "Epoch 700, Training Loss: 0.3550, Validation Loss: 0.5408\n",
      "Epoch 800, Training Loss: 0.3054, Validation Loss: 0.5665\n",
      "Epoch 900, Training Loss: 0.3167, Validation Loss: 0.5617\n",
      "Epoch 1000, Training Loss: 0.3190, Validation Loss: 0.5318\n",
      "PReLU Validation Loss: 0.4566\n",
      "Best Activation Function: ReLU() with Validation Loss: 0.4459\n",
      "submission.csv has been created.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▂▃▄▅▆▆▇█▁▂▃▃▄▅▅▆▇█▁▂▃▄▄▅▆▆▇█▁▂▃▃▄▅▆▇▇█</td></tr><tr><td>Training Loss</td><td>▇▄▃▃▂▂▂▂▂▂█▄▄▄▃▄▂▃▂▃█▄▄▃▂▄▂▃▁▁▇▅▃▄▃▂▂▂▁▁</td></tr><tr><td>Validation Loss</td><td>▅▂▂▃▃▃▅▅▆█▇▃▂▂▁▂▁▁▂▃▅▂▃▄▄▄▅▅▆█▅▃▂▂▃▅▃▃▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>1000</td></tr><tr><td>Training Loss</td><td>0.31897</td></tr><tr><td>Validation Loss</td><td>0.53184</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Run_2024-10-25_18-48-10</strong> at: <a href='https://wandb.ai/alstjr7141-korea-university-of-technology-and-education/titanic_training/runs/7mrje86e' target=\"_blank\">https://wandb.ai/alstjr7141-korea-university-of-technology-and-education/titanic_training/runs/7mrje86e</a><br/> View project at: <a href='https://wandb.ai/alstjr7141-korea-university-of-technology-and-education/titanic_training' target=\"_blank\">https://wandb.ai/alstjr7141-korea-university-of-technology-and-education/titanic_training</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241025_184810-7mrje86e\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 488
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![결과](https://github.com/MinSeokCSE/Deep/blob/main/kaggle.png?raw=true) ",
   "id": "d25bbc6363c9628a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<h3>[숙제후기]</h3><br>\n",
    "이번 과제를 통해 데이터 전처리, 모델 학습, 최종 예측에 이르는 전체 과정의 중요성을 체감할 수 있었습니다. 결측치 채우기와 범주형 데이터 변환을 통해 전처리의 중요성을 알게 되었고, DataLoader를 활용한 배치 단위 학습이 메모리 효율성을 높이는 데 효과적임을 배웠습니다.<br><br>\n",
    "\n",
    "특히, 여러 활성화 함수(ELU, ReLU, LeakyReLU, PReLU)를 비교하며 최적의 함수를 선택하는 과정이 흥미로웠고, LeakyReLU가 가장 좋은 성능을 보여 모델 튜닝의 중요성을 깨달았습니다. 또한 wandb로 실험 결과를 추적하며, 체계적으로 모델 성능을 평가하고 최종 제출 파일을 생성하는 데 큰 도움이 되었습니다.\n"
   ],
   "id": "411c9e660c9eeb8c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
